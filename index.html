<!DOCTYPE html>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Han-Jia Ye</title>
<meta content="Han-Jia Ye" name="Han-Jia Ye">
<link href="style.css" rel="stylesheet" type="text/css">
<script src=".jquery-1.11.1.min.js" type="text/javascript"></script>  
</head>

<body>
  <div class="menu"> 
<a aria-label="Back to group home page" href="https://www.lamda.nju.edu.cn/">	
<img alt="LAMDA Group" aria-hidden="true" width="110px" xml:space="preserve" src="./imgs/lamda.png"></a>
<a href="https://www.lamda.nju.edu.cn/yehj">Home</a> 
<a href="https://www.lamda.nju.edu.cn/yehj#publications">Publications</a> 
<a href="https://www.lamda.nju.edu.cn/yehj#teaching"> Teaching</a>
<a href="https://www.lamda.nju.edu.cn/yehj#students"> Students</a> 
<a href="https://www.lamda.nju.edu.cn/yehj#code"> Code</a> 
  </div>
  <div class="container">
    <table border="0">
      <tbody><tr>
        <td><img src="./imgs/yehj5.jpg" width="400"></td>
        <td style="width: 30px">&nbsp;</td>
        <td valign="top" width="600">
          <span class="name">Han-Jia Ye (叶翰嘉)</span>
          <p class="information">
           (Pre-Tenure) Associate Professor</p>
		  <p class="information"><a href="https://ai.nju.edu.cn/">School of Artificial Intelligence</a>, <a href="https://www.nju.edu.cn/">Nanjing University</a><br>
		  <a href="https://keysoftlab.nju.edu.cn/main.psp">State Key Laboratory for Novel Software Technology</a><br>
		  163 Xianlin Avenue, Qixia District, Nanjing, China
		  </p>
          <p class="information"><strong>Email</strong>: <span class="unselectable">ye<span class="mock">hj</span><span class="hide">xkxkxk</span>@nju.edu.cn</span><br>
		  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="unselectable">ye<span class="mock">hj</span><span class="hide">xkxkxk</span>@lamda.nju.edu.cn</span><br>
		  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<span class="unselectable">yhj<span class="mock">yehanjia</span><span class="hide">xkxkxk</span>@gmail.com</span>
		  </p>
        </td>
      </tr>
    </tbody></table>
    
	<!-- bio session -->
	<a id="bio" class="anchor"></a><span class="section">Short Bio</span>
	<p class="bio">Han-Jia Ye is an Associate Professor (Pre-Tenure) in the <a href="http://ai.nju.edu.cn/">School of Artificial Intelligence</a> at the <a href="http://www.nju.edu.cn/">Nanjing University</a> (NJU). His major research focuses on machine learning and its applications to data mining and computer vision, including representation learning, meta-learning, and model reuse. <br><br>

	Han-Jia received his B.Sc. degree from <a href="http://www.njupt.edu.cn/">Nanjing University of Posts and Telecommunications</a>, China in June 2013. After that, he became an M.Sc. student in the LAMDA Group led by professor <a href="http://cs.nju.edu.cn/zhouzh/">Zhi-Hua Zhou</a> in Nanjing University. From Sept. 2015, Han-Jia started his Ph.D. degree in machine learning under the supervision of Prof. <a href="http://www.lamda.nju.edu.cn/jiangy/">Yuan Jiang</a> and Prof. <a href="http://www.lamda.nju.edu.cn/zhandc/">De-Chuan Zhan</a>. 
	During 2017-2018, he visited Prof. <a href="http://www-bcf.usc.edu/~feisha/">Fei Sha</a>'s group in University of Southern California, LA. He received his PhD degree at May 2019.</p>

	<!-- news session -->
	<a id="news" class="anchor"></a><span class="section">Latest News</span>
	<ul>
	<li><p>06/2024: Release the <b><a href="https://github.com/qile2000/LAMDA-TALENT">Tabular Data Learning Toolbox TALENT</a></b>, <b><a href="https://arxiv.org/abs/2407.03257">a baseline ModernNCA</a></b>, as well as the <b><a href="https://arxiv.org/abs/2407.00956">benchmark</a></b>.</p>
	
	<li><p>06/2024: Release the <b><a href="https://arxiv.org/abs/2406.02539">Multilingual Multimodal Large Language Model Parrot</a></b>.</p>
	
	<li><p>06/2024: 1 <b><a href="https://arxiv.org/abs/2406.03496">arXiv paper</a></b> on Multimodal LLMs Learning without Text-only Forgetting.</p>
	
	<li><p>06/2024: Release the <b><a href="https://github.com/AIDC-AI/Ovis">OVIS Multimodal Large Language Model</a></b> [<a href="https://arxiv.org/abs/2405.20797">Paper</a>].</p>
	
	<li><p>05/2024: 4 papers have been accepted by ICML 2024.</p>
	
	<li><p>05/2024: 1 paper <b><a href="https://arxiv.org/abs/2304.05206">revisiting the channel independent strategy for multivariate time series forecasting</a></b> has been accepted by TKDE 2024.</p>

	<li><p>04/2024: 1 paper on <b><a href="https://arxiv.org/abs/2401.16386">continual learning with pre-trained model</a></b> has been accepted by IJCAI 2024 (survey track).</p>
		
	<li><p>03/2024: 2 papers have been accepted by CVPR 2024.</p>
	
	<li><p>02/2024: Glad to host a tutorial with <a href="https://yaoxiangding.github.io/">Yao-Xiang Ding</a> on model reuse at <a href="https://aaai.org/aaai-conference/aaai-24-tutorial-and-lab-forum/"> AAAI 2024</a>. Slides: [<a href="./slides/AAAI-2024-Tutorial-Part1.pdf">Part1</a>][<a href="https://drive.google.com/file/d/1pNls2tQnkTZYo9aGunRMQzo8HgdruII-/view">Part2</a>]</p>
	
	<li><p>12/2023: 2 papers have been accepted by AAAI 2024.</p>
	
	<li><p>09/2023: 2 papers have been accepted by NeurIPS 2023.</p>

	<li><p>09/2023: Release the <b><a href="https://github.com/sun-hailong/LAMDA-PILOT">Pre-Trained Model-Based Continual Learning Toolbox PILOT</a></b> [<a href="https://arxiv.org/abs/2309.07117">Report</a>][<a href="https://arxiv.org/abs/2401.16386">Survey</a>].</p>

	<li><p>09/2023: 1 paper on <b><a href="https://www.computer.org/csdl/journal/tp/5555/01/10256146/1QARFc4qd4A">contextualized meta-learning</a></b> has been accepted by TPAMI.</p>
	
	<li><p>08/2023: Release the <b><a href="https://github.com/zhangyikaii/LAMDA-ZhiJian">Model Reuse toolbox ZhiJian</a></b> [<a href="https://arxiv.org/abs/2308.09158">Report</a>][<a href="https://zhijian.readthedocs.io/en/latest/#">Documents</a>].</p>

	<li><p>08/2023: Glad to host a tutorial with <a href="https://wei-ying.net/">Ying Wei</a> and <a href="https://www.lamda.nju.edu.cn/zhoudw/">Da-Wei Zhou</a> on continual learning at <a href="https://ijcai-23.org/tutorials/">IJCAI 2023</a>. Slides: [<a href="https://www.lamda.nju.edu.cn/zhoudw/file/cl_tutorial.pdf">Part1</a>][<a href="./slides/IJCAI23-CIL-Tutorial-2.pdf
">Part2</a>]</p>

	<li><p>06/2023: 1 <b><a href="https://arxiv.org/abs/2306.03900">arXiv paper</a></b> on pre-trained model selection/ranking.</p>
	
	<li><p>02/2023: 1 <b><a href="https://arxiv.org/abs/2302.03648">survey paper</a></b> on deep class-incremental learning.</p>

	<li><p>01/2023: 3 papers have been accepted by ICLR 2023.</p>

	<li><p>08/2022: Very honored to serve as the Tutorial Co-Chairs of SDM 2023.

	<li><p>04/2022: 1 papers on <b><a href="https://arxiv.org/abs/2011.14663">unsupervised meta-learning</a></b> has been accepted by TPAMI.</p>

	<li><p>03/2022: 2 papers on <b><a href="https://arxiv.org/abs/2107.00197">meta-learning</a></b> and heterogeneous model reuse have been accepted by TPAMI.</p>

	<li><p>02/2022: Very honored to receive CCF Outstanding Doctoral Dissertation Award 2021.
	
	<!--
	<li><p>01/2022: 1 <b><a href="https://arxiv.org/abs/2106.16245">paper</a></b> on model-agnostic meta-learning has been accepted by ICLR 2022.</p>

	<li><p>06/2021: 1 <b><a href="https://arxiv.org/abs/2106.08112">arXiv paper</a></b> on contextualizing meta-learning.</p>

	<li><p>10/2021: Very honored to serve as the Doctoral Forum Co-Chairs of SDM 2022. <b><a href="https://www.siam.org/conferences/cm/program/special-events/sdm22-special-events">Call for Submissions</a></b>.

	<li><p>09/2021: 2 papers on meta-learning and fine-grained classification have been accepted by NeurIPS 2021.</p>

	<li><p>08/2021: 1 <b><a href="https://arxiv.org/abs/2104.01769">paper</a></b> on imbalanced deep learning accepted by ICCV 2021.</p>

	<li><p>07/2021: 1 <b><a href="https://arxiv.org/abs/2107.12654">paper</a></b> on incremental learning accepted by ACM MM 2021.</p>

	<li><p>07/2021: 1 <b><a href="https://arxiv.org/abs/2107.00197">arXiv paper</a></b> on meta-learning.</p>

	<li><p>06/2021: 1 <b><a href="https://arxiv.org/abs/2106.16245">arXiv paper</a></b> on model-agnostic meta-learning.</p>

	<li><p>06/2021: 1 <b><a href="https://arxiv.org/abs/2106.08112">arXiv paper</a></b> on contextualizing meta-learning.</p>

	<li><p>03/2021: 1 (oral) paper accepted by CVPR 2021 on <b><a href="https://arxiv.org/pdf/2103.15086.pdf">openset recognition</a></b>.</p>

	<li><p>12/2020: 3 papers accepted by AAAI 2021.</p>

	<li><p>09/2020: 1 paper accepted by IJCV on <b><a href="https://arxiv.org/abs/1906.02944">generalized few-shot learning</a></b>.</p>

	<li><p>04/2020: 1 paper accepted by TPAMI on <b><a href="https://ieeexplore.ieee.org/document/9093972">heterogeneous few-shot model reuse</a></b>.</p>

	<li><p>03/2020: 2 papers (1 oral and 1 poster) accepted by CVPR 2020.</p>

	<li><p>02/2020: 1 <b><a href="https://arxiv.org/abs/2002.00573">arXiv paper</a></b> on a novel perspective of meta-learning.</p>

	<li><p>01/2020: 1 <b><a href="https://arxiv.org/abs/2001.01385">arXiv paper</a></b> on imbalanced deep learning.</p>

	<li><p>10/2019: 1 paper accepted by TKDE on <b><a href="https://ieeexplore.ieee.org/abstract/document/8896009">multiple instance learning w/ novel class</a></b>.</p>

	<li><p>09/2019: Invited talk at a <b><a href="http://grid.hust.edu.cn/bigdata2019/content/index.html">CCF-Big Data</a></b> workshop (Wuhan, China) on "Multi-Metric Learning for Heterogeneous Data".</p>

	<li><p>09/2019: One manuscript with Xiang-Rong Sheng and De-Chuan Zhan is accepted by Machine Learning.</p>

	<li><p>07/2019: Joining the Nanjing University (School of Artificial Intelligence) as an Assistant Researcher.</p>

	<li><p>05/2019: Successfully defending thesis on "Metric Learning for Open Environment".</p>
	-->
	</li>
	</ul>

    <!-- Publication session -->
    <a id="publications" class="anchor"></a><span class="section">Selected Publications <a href="https://scholar.google.com/citations?user=mgOYhtoAAAAJ&hl=en"> [Google scholar]</a>&nbsp;<a href=https://dblp.uni-trier.de/pid/165/3014.html>[DBLP]</a> </span>
    <table border="0" width="98%" class="paper">
      <tbody>
	  <tr>
        <td>
          <img src="imgs/LastShot.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, Lu Ming, De-Chuan Zhan, Wei-Lun Chao.
		<strong>Few-Shot Learning with a Strong Teacher</strong>.
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. To appear.
          [<a href="https://arxiv.org/abs/2107.00197"><font color="#000080">pdf</font></a>]
          [<a href=https://github.com/Han-Jia/LastShot>code</font></a>]
        </td>
      </tr>
	  
      <tr>
        <td>
          <img src="imgs/UML.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, Lu Han, De-Chuan Zhan.
		<strong>Revisiting Unsupervised Meta-Learning via the Characteristics of Few-Shot Tasks</strong>.
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. 45(3): 3721-3737, 2021.
          [<a href="https://ieeexplore.ieee.org/document/9786650"><font color="#000080">pdf</font></a>]
          [<a href=https://github.com/hanlu-nju/revisiting-UML>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/ReFilled.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, Su Lu, De-Chuan Zhan.
		<strong>Generalized Knowledge Distillation via Relationship Matching</strong>. 
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. 45(2): 1817-1834, 2023.
          [<a href="https://ieeexplore.ieee.org/document/9737403/"><font color="#000080">pdf</font></a>]
          [<a href=https://github.com/njulus/REFILLED>code</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/ACA.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        Lu Han, <b>Han-Jia Ye</b>, De-Chuan Zhan.
		<strong>Augmentation Component Analysis: Modeling Similarity via the Augmentation Overlaps</strong>.
		In: <em>The 11th International Conference on Learning Representations (ICLR)</em> 2023. Kigali, Rwanda.
          [<a href="https://openreview.net/forum?id=5vM51iamNeL"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/hanlu-nju/AugCA>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/memo.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        Da-Wei Zhou, Qi-Wei Wang, <b>Han-Jia Ye</b>, De-Chuan Zhan.
		<strong>A Model or 603 Exemplars: Towards Memory-Efficient Class-Incremental Learning</strong>.
		In: <em>The 11th International Conference on Learning Representations (ICLR)</em> 2023. Kigali, Rwanda.
          [<a href="https://arxiv.org/abs/2205.13218"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/wangkiw/ICLR23-MEMO>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/UNICORN.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, Le Gan, De-Chuan Zhan.
		<strong>How to Train Your MAML to Excel in Few-Shot Classification</strong>.
		In: <em>The 10th International Conference on Learning Representations (ICLR)</em> 2022. Virtual.
          [<a href="https://openreview.net/forum?id=49h_IkpJtaE"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/Han-Jia/UNICORN-MAML>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/ReForm-PAMI.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou.
		<strong>Heterogeneous Few-Shot Model Rectification with Semantic Mapping</strong>.
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. 43(11): 3878-3891, 2021.
          [<a href="https://ieeexplore.ieee.org/document/9093972"><font color="#000080">pdf</font></a>]
          [<a href=http://www.lamda.nju.edu.cn/code_ReForm.ashx>code</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/MIEN.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        Xiu-Shen Wei*, <b>Han-Jia Ye</b>*, Xin Mu, Jianxin Wu, Chunhua Shen, Zhi-Hua Zhou.
		<strong>Multi-Instance Learning With Emerging Novel Class</strong>.
		<em>IEEE Transactions on Knowledge and Data Engineering</em>. 33(5): 2109-2120, 2021.
          [<a href="https://doi.org/10.1109/TKDE.2019.2952588"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/ST.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        Su Lu, <b>Han-Jia Ye</b>, Le Gan, De-Chuan Zhan.
		<strong>Towards Enabling Meta-Learning from Target Models</strong>.
		In: <em>Advances in Neural Information Processing Systems 34 (NeurIPS)</em> 2021: 8060--8071. Virtual.
          [<a href="https://proceedings.neurips.cc/paper/2021/hash/43baa6762fa81bb43b39c62553b2970d-Abstract.html"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/njulus/ST>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/TACO.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, Xin-Chun Li, De-Chuan Zhan.
		<strong>Task Cooperation for Semi-Supervised Few-Shot Learning</strong>.
		In: <em>Proceedings of the 35th AAAI Conference on Artificial Intelligence (AAAI)</em> 2021: 10682-10690. Virtual.
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17277"><font color="#000080">pdf</font></a>][<a href=https://github.com/lxcnju/TACO>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/MFW.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Wei-Lun Chao.
		<strong>Procrustean Training for Imbalanced Deep Learning</strong>.
		In: <em>Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)</em> 2021: 92--102. Montreal, Canada.
          [<a href="https://www.computer.org/csdl/proceedings-article/iccv/2021/281200a092/1BmHRS8bFWE"><font color="#000080">pdf</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/CDT.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, Hong-You Chen, De-Chuan Zhan, Wei-Lun Chao.
		<strong>Identifying and Compensating for Feature Deviation in Imbalanced Deep Learning</strong>.
		<em>CoRR abs/2001.01385</em>. 2020.
          [<a href="https://arxiv.org/abs/2001.01385"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/LIFT.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Nan Li, Yuan Jiang.
		<strong>Learning Multiple Local Metrics: Global Consideration Helps</strong>.
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. 42(7): 1698-1712, 2020.
          [<a href="https://ieeexplore.ieee.org/document/8653339"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/Aviator.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, Xiang-Rong Sheng, De-Chuan Zhan.
		<strong>Few-shot learning with adaptively initialized task optimizer: a practical meta-learning approach</strong>.
		<em>Machine Learning</em>. 109(3): 643-664, 2020.
          [<a href="https://doi.org/10.1007/s10994-019-05838-7"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/Han-Jia/AVIATOR>code</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/FEAT.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, Hexiang Hu, De-Chuan Zhan, Fei Sha.
		<strong>Few-Shot Learning via Embedding Adaptation With Set-to-Set Functions</strong>.
		In: <em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em> 2020: 8805--8814. Seattle, WA.
          [<a href="https://openaccess.thecvf.com/content_CVPR_2020/html/Ye_Few-Shot_Learning_via_Embedding_Adaptation_With_Set-to-Set_Functions_CVPR_2020_paper.html"><font color="#000080">pdf</font></a>]
		  [<a href=https://github.com/Sha-Lab/FEAT>code</font></a>]
        </td>
      </tr>
	  
	  <tr>
        <td>
          <img src="imgs/SemanticMetric.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou.
		<strong>What Makes Objects Similar: A Unified Multi-Metric Learning Approach</strong>.
		<em>IEEE Transactions on Pattern Analysis and Machine Intelligence</em>. 41(5): 1257-1270, 2019.
          [<a href="https://ieeexplore.ieee.org/document/8344546/"><font color="#000080">pdf</font></a>]
		  <a href="papers/UM2L_supp.pdf"><font color="#000080">[supp]</a>
          [<a href="code/UM2L Code.zip">code</font></a>]
        </td>
      </tr>  
	 
	  <tr>
        <td>
          <img src="imgs/Meta-Learning.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        Wei-Lun Chao*, <b>Han-Jia Ye</b>*, De-Chuan Zhan, Mark Campbell, Kilian Q. Weinberger.
		<strong>A Meta Understanding of Meta-Learning</strong>.
		In: <em>The Adaptive and Multitask Learning (AMTL) 2019 Workshop</em> 2019. Long Beach, CA.
          [<a href="https://arxiv.org/abs/2002.00573"><font color="#000080">pdf</font></a>]
        </td>
      </tr> 
	  
	  <tr>
        <td>
          <img src="imgs/MLJ-Theory.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang.
		<strong>Fast generalization rates for distance metric learning</strong>.
		<em>Machine Learning</em>. 108(2): 267-295, 2019.
          [<a href="https://link.springer.com/article/10.1007/s10994-018-5734-0"><font color="#000080">pdf</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/ReForm.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou.
		<strong>Rectify Heterogeneous Models with Semantic Mapping</strong>.
		In: <em>Proceedings of the 35th International Conference on Machine Learning (ICML) </em> 2018: 1904-1913. Stockholm, Sweden.
          [<a href="http://proceedings.mlr.press/v80/ye2018c/ye2018c.pdf"><font color="#000080">pdf</font></a>]
          [<a href=http://www.lamda.nju.edu.cn/code_ReForm.ashx>code</font></a>]
        </td>
      </tr>  

      <tr>
        <td>
          <img src="./imgs/DRIFT_Illustration.jpg" class="PaperThumbnail" width="120">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Xue-Min Si, Yuan Jiang.
          <strong>Learning Mahalanobis Distance Metric: Considering Instance Disturbance Helps</strong>. 
		  In: <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI) </em> 2018: 3315-3321. Melbourne, Australia.
          [<a href="https://www.ijcai.org/proceedings/2017/463"><font color="#000080">pdf</font></a>]
          [<a href="code/DRIFT_Code.zip"><font color="#000080">code</font></a>]
        </td>
      </tr>  
	  
	  <tr>
        <td>
          <img src="imgs/UM2L_Illustration.jpg" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang, Zhi-Hua Zhou.
		<strong>What Makes Objects Similar: A Unified Multi-Metric Learning Approach</strong>.
		In: <em>Advances in Neural Information Processing Systems 29 (NIPS)</em> 2016: 1235-1243. Barcelona, Spain.
          [<a href="https://proceedings.neurips.cc/paper/2016/hash/8fecb20817b3847419bb3de39a609afe-Abstract.html"><font color="#000080">pdf</font></a>]
          [<a href="code/UM2L Code.zip">code</font></a>]
        </td>
      </tr> 
	  
	  <tr>
        <td>
          <img src="imgs/ISMETS_Illustration.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px">		
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Jiang.
		<strong>Instance Specific Metric Subspace Learning: A Bayesian Approach</strong>.
		In: <em>Proceedings of the 30th AAAI Conference on Artificial Intelligence (AAAI)</em> 2016: 2272--2278. Phoenix, AR.
          [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/10264"><font color="#000080">pdf</font></a>]
        </td>
      </tr> 
	  
	  <tr>
        <td>
          <img src="imgs/RANC_Illustration.png" class="PaperThumbnail" width="240">
        </td>
		<td style="width: 30px">&nbsp;</td>
        <td style="padding-left: 15px" bgcolor="#e9eaed">
        <b>Han-Jia Ye</b>, De-Chuan Zhan, Yuan Miao, Yuan Jiang, Zhi-Hua Zhou.
		<strong>Rank Consistency based Multi-View Learning: A Privacy-Preserving Approach</strong>.
		In: <em>Proceedings of the 24th ACM International Conference on Information and Knowledge Management (CIKM)</em> 2015: 991--1000. Melbourne, Australia.
          [<a href="https://dl.acm.org/doi/10.1145/2806416.2806552"><font color="#000080">pdf</font></a>]
          [<a href="code/RANC code.zip">code</font></a>]
        </td>
      </tr>
    </tbody></table>

<!-- Teaching session -->
<a id="teaching" class="name"></a><span class="section">Services </span>
	<p class="service">Tutorial Co-Chair for <a href="https://www.siam.org/conferences/cm/conference/sdm23">SDM 2023</a></p>
    <p class="service">Doctoral Forum Co-Chair for <a href="https://www.siam.org/conferences/cm/conference/sdm22">SDM 2022</a></p>
	<p class="service">
      Area Chair for ICML 2024, CVPR 2024, SDM 2023, SDM 2022, ECML 2020. Senior PC Member for IJCAI 2021.
    </p>
    <p class="service">
      Reviewer for JMLR, TPAMI, AIJ, TKDE, TKDD, MLJ, etc.
    </p>    
	<p class="service">
      Reviewer/PC Member for ICML/NeurIPS/ICLR/AAAI/IJCAI/CVPR/ICCV, etc.
    </p>  	

<!-- Teaching session -->
<a id="bio" class="name"></a><span class="section">Teaching </span>
  <ul>
  <font color="#444444" face="Arial" size="4">    
     <li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/TSA2024">Time Series Analysis</a></b>. (For undergraduate and graduate students, Autumn, 2024)</p></li>
	<li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/ml2024fall/ml2024.htm">Introduction to Machine Learning</a></b>. (For undergraduate and graduate students, Autumn, 2024)</p>
	</li>
   <li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/TSA2023">Time Series Analysis</a></b>. (For undergraduate and graduate students, Autumn, 2023)</p></li>
	<li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/ml2023fall/ml2023.htm">Introduction to Machine Learning</a></b>. (For undergraduate and graduate students, Autumn, 2023)</p>
	</li>
   <li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/TSA2022">Time Series Analysis</a></b>. (For undergraduate and graduate students, Autumn, 2022)</p></li>
	<li><p><b><a href="https://cs.nju.edu.cn/zhouzh/zhouzh.files/course/ml.htm">Introduction to Machine Learning</a></b>. (With Prof. Zhi-Hua Zhou; For undergraduate and graduate students, Autumn, 2022)</p>
	</li>
	<li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/ml2022/ml2022.html">Introduction to Machine Learning</a></b>. (For undergraduate students, Spring, 2022)</p></li>
	<li><p><b><a href="https://www.lamda.nju.edu.cn/yehj/dsp2021">Digital Singal Processing</a></b>. (For undergraduate and graduate students, Autumn, 2021)</p></li>
  </font>
  </ul>
              
    <!-- Students session -->
<a id="students" class="name"></a><span class="section">Students </span>
  <ul>
  <font color="#444444" face="Arial" size="4">    
   <li> <b><a href="http://www.lamda.nju.edu.cn/wangqiwei/">Qi-Wei Wang</a></b>, 2021-2024  </li>   
   <li> <b><a href="http://www.lamda.nju.edu.cn/zhangyk/">  Yi-Kai Zhang </a></b>, 2021-  </li>   
   <li> <b><a href="http://www.lamda.nju.edu.cn/huangtj/"> Ting-Ji Huang </a></b>, 2022- </li>
   <li> <b><a href="http://www.lamda.nju.edu.cn/renl/"> Lu Ren </a></b>, 2022-  </li>    
   <li> <b><a href="http://www.lamda.nju.edu.cn/yic/"> Chao Yi </a></b>, 2022-  </li>    
   <li> <b><a href="http://www.lamda.nju.edu.cn/zhouql/"> Qi-Le Zhou </a></b>, 2022-  </li>
   <li> <b><a href="http://www.lamda.nju.edu.cn/chenxy/"> Xu-Yang Chen </a></b>, 2023-  </li>
   <li> <b><a href="http://www.lamda.nju.edu.cn/sunhl/"> Hai-Long Sun </a></b>, 2023-  </li>
   <li> <b><a href="http://www.lamda.nju.edu.cn/yinhh/">Huai-Hong Yin</a></b>, 2023-  </li>
   <li> <b><a href="http://www.lamda.nju.edu.cn/zhout/">Tao Zhou</a></b>, 2023-  </li><br>
  </font>
  </ul>
  
  <!-- Code session -->
<a id="code" class="name"></a><span class="section">Code </span>
  <ul>
  <font color="#444444" face="Arial" size="4">    
    <li> Learning with Tabular Data <a href="https://github.com/qile2000/LAMDA-TALENT">[Toolbox]</a> <a href="https://arxiv.org/abs/2407.03257">[Baseline]</a> <a href="https://arxiv.org/abs/2407.00956">[Benchmark]</a></li>      
    <li> Model Reuse <a href="https://github.com/zhangyikaii/LAMDA-ZhiJian">[Toolbox]</a> <a href="https://arxiv.org/abs/2308.09158">[Report]</a> </li>   
   <li> Representation-based Few-Shot Learning <a href="https://github.com/Sha-Lab/FEAT/">[Supervised Toolbox]</a> <a href="https://github.com/hanlu-nju/revisiting-UML">[Unsupervised Toolbox]</a> </li>   
   <li> Class-Incremental Learning <a href="https://github.com/G-U-N/PyCIL">[Toolbox]</a> <a href="https://github.com/sun-hailong/LAMDA-PILOT">[Pre-Trained Model-Based Toolbox]</a> <a href="https://arxiv.org/abs/2302.03648">[Survey1]</a><a href="https://arxiv.org/abs/2401.16386">[Survey2]</a> <a href="http://www.lamda.nju.edu.cn/zhoudw/file/cil_survey.pdf">[Survey in Chinese]</a></li>   
  </font>
  </ul>

  <p><font color="#444444" face="Arial" size="2">Last Update@2024.05 by Han-Jia Ye. Thanks <a href="https://deqings.github.io/index.html"><font color="#000080">Dr. Deqing Sun</font></a> and <a href="http://people.csail.mit.edu/celiu"><font color="#000080">Dr. Ce Liu</font></a> for the template. </font></p>

  </div>
  <script>
    var thumbnails = document.getElementsByClassName("PaperThumbnail");
    var i;
    for (i = 0; i < thumbnails.length; i++) {
      thumbnails[i].width = "260"
    }
  </script>  


</body></html>
